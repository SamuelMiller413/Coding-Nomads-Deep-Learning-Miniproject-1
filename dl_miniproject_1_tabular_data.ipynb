{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dl_miniproject_1_tabular_data.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "TppBhRBlJDVY",
        "FeNWY55nK_BL",
        "k2LeKUflLehC",
        "c8XPEDl7ocFX",
        "D-_gt2iopuDn",
        "YUK7yRtEp2NA",
        "Q_arrqLoqADy"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamuelMiller413/Coding-Nomads-Deep-Learning-Miniproject-1/blob/master/dl_miniproject_1_tabular_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Intrdouction\n",
        "---"
      ],
      "metadata": {
        "id": "s4ExnDwUNcsf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem Statement:\n",
        "> An automobile company has plans to enter new markets with their existing products (P1, P2, P3, P4 and P5). After intensive market research, theyâ€™ve deduced that the behavior of new market is similar to their existing market.\n",
        "\n",
        ">In their existing market, the sales team has classified all customers into 4 segments (A, B, C, D ). Then, they performed segmented outreach and communication for different segment of customers. This strategy has work exceptionally well for them. They plan to use the same strategy on new markets and have identified 2627 new potential customers.\n",
        "\n",
        ">You are required to help the manager to predict the right group of the new customers."
      ],
      "metadata": {
        "id": "D3o_wBWZOeNf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resources\n",
        ">Data    (from Kaggle)\n",
        "* [Customer Segmentation Dataset](https://www.kaggle.com/datasets/abisheksudarshan/customer-segmentation?select=train.csv) \n",
        "\n",
        "> Notebooks of Influence\n",
        "* [Janatahack](https://www.kaggle.com/code/abisheksudarshan/av-janatahack-customer-segmentation/data) \n",
        "* [Seun Ayegboyin](https://www.kaggle.com/code/seunayegboyin/customer-segmentation-with-kmeans-and-pca) (PCA/Clustering)"
      ],
      "metadata": {
        "id": "tm-Dt4BOOkue"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Work Flow\n",
        "---\n",
        "\n",
        "### NOTES\n",
        "* Write \n",
        "        def grep()\n",
        "        def greps_all()\n",
        "* OHE all\n",
        "* Impute NaN\n",
        "* Train Models\n",
        "* Train DL Models\n"
      ],
      "metadata": {
        "id": "bphRi4fLDrNB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Workflow Outline\n",
        "\n",
        "---\n",
        "#### 1. Pre-Training\n",
        "---\n",
        "* Setup\n",
        "    * Data Loading\n",
        "    * Download the Dataset\n",
        "* EDA & Data Visualization\n",
        "* Feature Engineering and Transformation\n",
        "* Pipelines\n",
        "<br>\n",
        "---\n",
        "#### 2. Training\n",
        "---\n",
        "* Traditional ML Modeling\n",
        "* Pure Torch Model\n",
        "* High-level Libraries and Tabular Frameworks\n",
        "<br>\n",
        "---\n",
        "#### 3. Testing\n",
        "---\n",
        "* Model Selection and Test Set Evaluation\n",
        "* Notes and Findings\n",
        "\n"
      ],
      "metadata": {
        "id": "3Qg8oAt7FHzL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 1. Pre-Training\n",
        "---\n",
        "* Setup\n",
        "    * Data Loading\n",
        "    * Download the Dataset\n",
        "* EDA & Data Visualization\n",
        "    * Data Viz Functions\n",
        "* Feature Engineering and Transformation\n",
        "* Pipelines"
      ],
      "metadata": {
        "id": "CcXjCgnEHuod"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading and Splitting"
      ],
      "metadata": {
        "id": "TppBhRBlJDVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndEWFz-qZTAk",
        "outputId": "cab094a1-3696-484b-dc40-27e693012b73"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# upload 'kaggle.json'\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "id": "P4ZxddsPcaI5",
        "outputId": "045ebac1-1595-4f7f-e033-520555a944e9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-264b267c-8d5e-41ee-8787-5053e474c7ae\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-264b267c-8d5e-41ee-8787-5053e474c7ae\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"samuelmiller413\",\"key\":\"d635e1518efc064bb478bb67bb2c22aa\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make kaggle directory \n",
        "! mkdir ~/.kaggle\n",
        "# store JSON\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "# change permissions\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# download data from kaggle\n",
        "! kaggle datasets download -d 'abisheksudarshan/customer-segmentation'\n",
        "# make directory for data\n",
        "! mkdir customer-segmentation\n",
        "\n",
        "# unzip into directory\n",
        "! cd.. customer-segmentation/\n",
        "! unzip customer-segmentation.zip -d customer-segmentation/\n",
        "# remove .zip\n",
        "! rm -r customer-segmentation.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiYUS7XVcrgW",
        "outputId": "5095bd58-15f0-4c38-e647-917da434c90b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory â€˜/root/.kaggleâ€™: File exists\n",
            "Downloading customer-segmentation.zip to /content\n",
            "  0% 0.00/98.7k [00:00<?, ?B/s]\n",
            "100% 98.7k/98.7k [00:00<00:00, 42.3MB/s]\n",
            "mkdir: cannot create directory â€˜customer-segmentationâ€™: File exists\n",
            "/bin/bash: cd..: command not found\n",
            "Archive:  customer-segmentation.zip\n",
            "replace customer-segmentation/test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Setup"
      ],
      "metadata": {
        "id": "oi-C2we-Jm62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# import libraries\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import pprint\n",
        "import inspect\n",
        "                                                                          # PRE-PROCESSING\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "                                                                          # FEATURE SELECTION\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from sklearn.feature_selection import SelectFromModel, mutual_info_regression, RFE, RFECV\n",
        "\n",
        "                                                                          # PIPELINE\n",
        "from sklearn.pipeline import Pipeline\n",
        "                                          \n",
        "                                                                          # NEURAL NETWORK\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "                                                                          # CROSS VALIDATION\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, ShuffleSplit, StratifiedKFold\n",
        "from sklearn.model_selection import learning_curve, cross_val_predict\n",
        "from sklearn.model_selection import KFold, RandomizedSearchCV\n",
        "\n",
        "                                                                          # EVALUATION\n",
        "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.metrics import SCORERS\n",
        "\n",
        "                                                                          # PLOTTING\n",
        "# from plotting import plot_learning_curve, plot_validation_curve\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "jiMUo9UNJbQ8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Download Dataset"
      ],
      "metadata": {
        "id": "hzPonF2gJSGJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_train = '/content/customer-segmentation/train.csv'\n",
        "csv_test = '/content/customer-segmentation/test.csv'"
      ],
      "metadata": {
        "id": "zU6xhRJeqW6u"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Split Data"
      ],
      "metadata": {
        "id": "Ub5Kk1R8JUGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# > data is pre-split into two files <\n",
        "# read split data\n",
        "train = pd.read_csv(csv_train)\n",
        "test = pd.read_csv(csv_test)\n",
        "# meta encode whether df is 'train'\n",
        "train['train_y_n']=1\n",
        "test['train_y_n']=0\n",
        "# make full df\n",
        "full_df = pd.concat([train, test])"
      ],
      "metadata": {
        "id": "rbk91B4yyCJ6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mini dataframes\n",
        "comp_df1 = full_df.loc[full_df['train_y_n'] == 1].head()\n",
        "comp_df2 = full_df.loc[full_df['train_y_n'] == 0].tail()\n",
        "comps_df = pd.concat([comp_df1, comp_df2])\n",
        "# list dfs and verify their datatype\n",
        "df_dict = {'train':train, 'test':test, 'full_df':full_df, 'comp_df1':comp_df1, 'comp_df2':comp_df2, 'comps_df':comps_df}\n",
        "print([type(v) for k,v in df_dict.items()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-kfjEcy5mo6",
        "outputId": "8a4d092e-13a4-442a-e6bc-ca7fbe0cf531"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<class 'pandas.core.frame.DataFrame'>, <class 'pandas.core.frame.DataFrame'>, <class 'pandas.core.frame.DataFrame'>, <class 'pandas.core.frame.DataFrame'>, <class 'pandas.core.frame.DataFrame'>, <class 'pandas.core.frame.DataFrame'>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "len(df_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRTidV3A-Tn5",
        "outputId": "9c3eb3c4-698f-4fd6-bc5e-338933de4eec"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# scoping the dataframes\n",
        "\n",
        "# shapes\n",
        "print('\\n---\\nShapes\\n---\\n')\n",
        "[print(f\"{k.upper()} : {v.shape}\\n\") for k,v in df_dict.items()]\n",
        "print(\"\\n=====================\\n\")\n",
        "# columns\n",
        "print('\\n---\\nColumns\\n---\\n')\n",
        "[print(f\"\\n---\\n{k.upper()} Columns: \\n---\\n\\n{v.columns}\\n\") for k,v in df_dict.items()]\n",
        "print(\"\\n=====================\\n\")\n",
        "# samples\n",
        "print(\"\\n---\\nSamples\\n---\\n\")\n",
        "[print(f\"\\n---\\n{k.upper()} Samples: \\n---\\n\\n{v.sample(5)}\\n\\n\\n\") for k,v in df_dict.items()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nU3o1GJ0zCq8",
        "outputId": "95a5f609-7240-41e8-dc92-aa08d200613f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---\n",
            "Shapes\n",
            "---\n",
            "\n",
            "TRAIN : (8068, 12)\n",
            "\n",
            "TEST : (2627, 11)\n",
            "\n",
            "FULL_DF : (10695, 12)\n",
            "\n",
            "COMP_DF1 : (5, 12)\n",
            "\n",
            "COMP_DF2 : (5, 12)\n",
            "\n",
            "COMPS_DF : (10, 12)\n",
            "\n",
            "\n",
            "=====================\n",
            "\n",
            "\n",
            "---\n",
            "Columns\n",
            "---\n",
            "\n",
            "\n",
            "---\n",
            "TRAIN Columns: \n",
            "---\n",
            "\n",
            "Index(['ID', 'Gender', 'Ever_Married', 'Age', 'Graduated', 'Profession',\n",
            "       'Work_Experience', 'Spending_Score', 'Family_Size', 'Var_1',\n",
            "       'Segmentation', 'train_y_n'],\n",
            "      dtype='object')\n",
            "\n",
            "\n",
            "---\n",
            "TEST Columns: \n",
            "---\n",
            "\n",
            "Index(['ID', 'Gender', 'Ever_Married', 'Age', 'Graduated', 'Profession',\n",
            "       'Work_Experience', 'Spending_Score', 'Family_Size', 'Var_1',\n",
            "       'train_y_n'],\n",
            "      dtype='object')\n",
            "\n",
            "\n",
            "---\n",
            "FULL_DF Columns: \n",
            "---\n",
            "\n",
            "Index(['ID', 'Gender', 'Ever_Married', 'Age', 'Graduated', 'Profession',\n",
            "       'Work_Experience', 'Spending_Score', 'Family_Size', 'Var_1',\n",
            "       'Segmentation', 'train_y_n'],\n",
            "      dtype='object')\n",
            "\n",
            "\n",
            "---\n",
            "COMP_DF1 Columns: \n",
            "---\n",
            "\n",
            "Index(['ID', 'Gender', 'Ever_Married', 'Age', 'Graduated', 'Profession',\n",
            "       'Work_Experience', 'Spending_Score', 'Family_Size', 'Var_1',\n",
            "       'Segmentation', 'train_y_n'],\n",
            "      dtype='object')\n",
            "\n",
            "\n",
            "---\n",
            "COMP_DF2 Columns: \n",
            "---\n",
            "\n",
            "Index(['ID', 'Gender', 'Ever_Married', 'Age', 'Graduated', 'Profession',\n",
            "       'Work_Experience', 'Spending_Score', 'Family_Size', 'Var_1',\n",
            "       'Segmentation', 'train_y_n'],\n",
            "      dtype='object')\n",
            "\n",
            "\n",
            "---\n",
            "COMPS_DF Columns: \n",
            "---\n",
            "\n",
            "Index(['ID', 'Gender', 'Ever_Married', 'Age', 'Graduated', 'Profession',\n",
            "       'Work_Experience', 'Spending_Score', 'Family_Size', 'Var_1',\n",
            "       'Segmentation', 'train_y_n'],\n",
            "      dtype='object')\n",
            "\n",
            "\n",
            "=====================\n",
            "\n",
            "\n",
            "---\n",
            "Samples\n",
            "---\n",
            "\n",
            "\n",
            "---\n",
            "TRAIN Samples: \n",
            "---\n",
            "\n",
            "          ID  Gender Ever_Married  Age Graduated Profession  Work_Experience  \\\n",
            "5983  462954  Female          Yes   48       Yes  Homemaker             12.0   \n",
            "2213  460898    Male          Yes   48        No     Artist              3.0   \n",
            "5360  460110  Female           No   52       Yes     Artist              0.0   \n",
            "586   461608  Female          Yes   56       Yes  Executive              NaN   \n",
            "14    460849  Female          Yes   58        No     Doctor              0.0   \n",
            "\n",
            "     Spending_Score  Family_Size  Var_1 Segmentation  train_y_n  \n",
            "5983            Low          1.0  Cat_6            A          1  \n",
            "2213        Average          4.0  Cat_6            B          1  \n",
            "5360            Low          2.0    NaN            C          1  \n",
            "586            High          4.0  Cat_1            A          1  \n",
            "14              Low          1.0  Cat_3            B          1  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "---\n",
            "TEST Samples: \n",
            "---\n",
            "\n",
            "          ID  Gender Ever_Married  Age Graduated  Profession  Work_Experience  \\\n",
            "2584  467849  Female          Yes   39       Yes      Doctor              0.0   \n",
            "1121  462738  Female           No   33       Yes  Healthcare              NaN   \n",
            "2382  467157    Male          Yes   39       Yes   Executive              8.0   \n",
            "514   460640    Male          Yes   86       NaN      Lawyer              NaN   \n",
            "1567  464286  Female          Yes   57       Yes      Artist              0.0   \n",
            "\n",
            "     Spending_Score  Family_Size  Var_1  train_y_n  \n",
            "2584            Low          1.0  Cat_2          0  \n",
            "1121            Low          3.0  Cat_2          0  \n",
            "2382           High          6.0  Cat_7          0  \n",
            "514             Low          1.0  Cat_3          0  \n",
            "1567        Average          2.0  Cat_6          0  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "---\n",
            "FULL_DF Samples: \n",
            "---\n",
            "\n",
            "          ID  Gender Ever_Married  Age Graduated     Profession  \\\n",
            "2565  467259    Male          Yes   70       Yes         Lawyer   \n",
            "6393  466141  Female          Yes   60       Yes      Homemaker   \n",
            "2238  459875    Male          Yes   71        No         Lawyer   \n",
            "5715  463458    Male          Yes   26       Yes  Entertainment   \n",
            "4793  466106  Female          Yes   63        No         Artist   \n",
            "\n",
            "      Work_Experience Spending_Score  Family_Size  Var_1 Segmentation  \\\n",
            "2565              1.0           High          2.0  Cat_6            B   \n",
            "6393              1.0            Low          4.0  Cat_6            C   \n",
            "2238              0.0           High          NaN  Cat_6            A   \n",
            "5715              1.0        Average          2.0  Cat_6            B   \n",
            "4793              0.0        Average          5.0  Cat_6            C   \n",
            "\n",
            "      train_y_n  \n",
            "2565          1  \n",
            "6393          1  \n",
            "2238          1  \n",
            "5715          1  \n",
            "4793          1  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "---\n",
            "COMP_DF1 Samples: \n",
            "---\n",
            "\n",
            "       ID  Gender Ever_Married  Age Graduated     Profession  Work_Experience  \\\n",
            "4  462669  Female          Yes   40       Yes  Entertainment              NaN   \n",
            "1  462643  Female          Yes   38       Yes       Engineer              NaN   \n",
            "0  462809    Male           No   22        No     Healthcare              1.0   \n",
            "2  466315  Female          Yes   67       Yes       Engineer              1.0   \n",
            "3  461735    Male          Yes   67       Yes         Lawyer              0.0   \n",
            "\n",
            "  Spending_Score  Family_Size  Var_1 Segmentation  train_y_n  \n",
            "4           High          6.0  Cat_6            A          1  \n",
            "1        Average          3.0  Cat_4            A          1  \n",
            "0            Low          4.0  Cat_4            D          1  \n",
            "2            Low          1.0  Cat_6            B          1  \n",
            "3           High          2.0  Cat_6            B          1  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "---\n",
            "COMP_DF2 Samples: \n",
            "---\n",
            "\n",
            "          ID  Gender Ever_Married  Age Graduated     Profession  \\\n",
            "2622  467954    Male           No   29        No     Healthcare   \n",
            "2624  467960  Female           No   53       Yes  Entertainment   \n",
            "2623  467958  Female           No   35       Yes         Doctor   \n",
            "2626  467968  Female           No   43       Yes     Healthcare   \n",
            "2625  467961    Male          Yes   47       Yes      Executive   \n",
            "\n",
            "      Work_Experience Spending_Score  Family_Size  Var_1 Segmentation  \\\n",
            "2622              9.0            Low          4.0  Cat_6          NaN   \n",
            "2624              NaN            Low          2.0  Cat_6          NaN   \n",
            "2623              1.0            Low          1.0  Cat_6          NaN   \n",
            "2626              9.0            Low          3.0  Cat_7          NaN   \n",
            "2625              1.0           High          5.0  Cat_4          NaN   \n",
            "\n",
            "      train_y_n  \n",
            "2622          0  \n",
            "2624          0  \n",
            "2623          0  \n",
            "2626          0  \n",
            "2625          0  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "---\n",
            "COMPS_DF Samples: \n",
            "---\n",
            "\n",
            "          ID  Gender Ever_Married  Age Graduated     Profession  \\\n",
            "2622  467954    Male           No   29        No     Healthcare   \n",
            "2     466315  Female          Yes   67       Yes       Engineer   \n",
            "2624  467960  Female           No   53       Yes  Entertainment   \n",
            "2625  467961    Male          Yes   47       Yes      Executive   \n",
            "2623  467958  Female           No   35       Yes         Doctor   \n",
            "\n",
            "      Work_Experience Spending_Score  Family_Size  Var_1 Segmentation  \\\n",
            "2622              9.0            Low          4.0  Cat_6          NaN   \n",
            "2                 1.0            Low          1.0  Cat_6            B   \n",
            "2624              NaN            Low          2.0  Cat_6          NaN   \n",
            "2625              1.0           High          5.0  Cat_4          NaN   \n",
            "2623              1.0            Low          1.0  Cat_6          NaN   \n",
            "\n",
            "      train_y_n  \n",
            "2622          0  \n",
            "2             1  \n",
            "2624          0  \n",
            "2625          0  \n",
            "2623          0  \n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None, None, None, None, None]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EDA & Data Visualization"
      ],
      "metadata": {
        "id": "FeNWY55nK_BL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### EDA Functions"
      ],
      "metadata": {
        "id": "fkEaX-z0rgAK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Retrieve Variable Name"
      ],
      "metadata": {
        "id": "Ie3tiq1olufG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_name(var):\n",
        "    callers_local_vars = inspect.currentframe().f_back.f_back.f_locals.items()\n",
        "    return [var_name for var_name, var_val in callers_local_vars if var_val is var]\n",
        "    # above code --> https://stackoverflow.com/questions/18425225/getting-the-name-of-a-variable-as-a-string\n",
        "                            # user: scohe001"
      ],
      "metadata": {
        "id": "jHKAVsWXlz9Q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Summary Function"
      ],
      "metadata": {
        "id": "32tesO8_sxxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize(subset=train):\n",
        "    '''\n",
        "    Doc:\n",
        "    Summarizes EDA for Pandas dataframe.\n",
        "\n",
        "        Parameters\n",
        "        -------------\n",
        "            subset      : (dataframe)\n",
        "                Specify the dataframe or subset of dataframe to summarize\n",
        "                    default: 'train'\n",
        "        Returns\n",
        "        -------------\n",
        "            Summary functions from those stored in eda_summary\n",
        "    '''\n",
        "    # initialize summary dict\n",
        "    eda_summary = {\n",
        "        'describe':subset.describe, \n",
        "        'info':subset.info, \n",
        "        'shape':subset.shape, \n",
        "        'isnull':subset.isnull,\n",
        "        'corr':subset.corr,\n",
        "        'dtypes':subset.dtypes\n",
        "        }\n",
        "\n",
        "    # display name of subset\n",
        "    print(f\"\\nSummary of Subset:  '{retrieve_name(subset)[0]}'\\n\")\n",
        "    # loop through and call each summary function\n",
        "    for k,v in eda_summary.items():\n",
        "        if k == 'isnull':\n",
        "            v = eda_summary[k]().sum()\n",
        "            print(f\"\\n--------\\n{k.upper()}\\n--------\\n\\n{v}\\n---\")    \n",
        "        else:\n",
        "            print(f\"\\n--------\\n{k.upper()}\\n--------\\n\\n{v}\\n---\")"
      ],
      "metadata": {
        "id": "3fsKB3jwG2RG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Data Viz Functions"
      ],
      "metadata": {
        "id": "4AUNzBi2XTdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set target variable\n",
        "target = 'segmentation'          # <--- needs scaling\n",
        "sizes = {'s':((10,6)),'m':(14,8), 'l':(18,10)}"
      ],
      "metadata": {
        "id": "8ZIAL430I1K6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_grep(feature, label=target, plot_type='countplot', fig_size='s',subset=train): \n",
        "    '''\n",
        "    Doc:\n",
        "    Greps feature with label.\n",
        "    Displays a seaborn plot of grep.\n",
        "\n",
        "        Parameters\n",
        "        -------------\n",
        "            feature   : (str)\n",
        "                Feature to plot 'label' by\n",
        "            label     : (str)    \n",
        "                Label (or additional feature) to plot 'feature' by  \n",
        "                default   = target\n",
        "                    * save a variable 'target' as df.columns['target variable']               \n",
        "            plot_type : (dict)\n",
        "                Specify a seaborn plot function from {graph_}\n",
        "                    default: 'countplot'      \n",
        "            fig_size  : {'s', 'm', 'l'}\n",
        "                Choose a small , medium, or large figure size\n",
        "                default   : {'s'=10x6, 'm'=14x8, 'l'=18x10}\n",
        "            subset    : (dataframe)\n",
        "                Specify which subset of the dataframe to use\n",
        "                default   = 'train'\n",
        "                examples  : 'train', 'test','all', etc.\n",
        "        \n",
        "        Returns\n",
        "        -------------\n",
        "            Seaborn plot of grep(feature,label)\n",
        "\n",
        "        Plot Options: \n",
        "        -------------\n",
        "        --> from Seaborn API Reference : https://seaborn.pydata.org/api.html\n",
        "        \n",
        "        Relational Plots\n",
        "        ---\n",
        "        'relplot'     - Figure-level interface for drawing relational plots onto a FacetGrid.\n",
        "        'scatterplot' - Draw a scatter plot with possibility of several semantic groupings.\n",
        "        'lineplot'    - Draw a line plot with possibility of several semantic groupings.\n",
        "\n",
        "        Distribution Plots\n",
        "        ---\n",
        "        'displot'     - Figure-level interface for drawing distribution plots onto a FacetGrid.\n",
        "        'histplot'    - Plot univariate or bivariate histograms to show distributions of datasets.\n",
        "        'kdeplot'     - Plot univariate or bivariate distributions using kernel density estimation.\n",
        "\n",
        "        Categorical Plots\n",
        "        ---\n",
        "        'ecdfplot'    - Plot empirical cumulative distribution functions.\n",
        "        'rugplot'     - Plot marginal distributions by drawing ticks along the x and y axes.\n",
        "        'catplot'     - Figure-level interface for drawing categorical plots onto a FacetGrid.\n",
        "        'stripplot'   - Draw a scatterplot where one variable is categorical.\n",
        "        'swarmplot'   - Draw a categorical scatterplot with non-overlapping points.\n",
        "        'boxplot'     - Draw a box plot to show distributions with respect to categories.\n",
        "        'violinplot'  - Draw a combination of boxplot and kernel density estimate.\n",
        "        'boxenplot'   - Draw an enhanced box plot for larger datasets\n",
        "        'pointplot'   - Show point estimates and confidence intervals using scatter plot glyphs.\n",
        "        'barplot'     - Show point estimates and confidence intervals as rectangular bars.\n",
        "        'countplot'   - Show the counts of observations in each categorical bin using bars.\n",
        "\n",
        "        Regression Plots\n",
        "        ---\n",
        "        'lmplot'      - Plot data and regression model fits across a FacetGrid.\n",
        "        'regplot'     - Plot data and a linear regression model fit.\n",
        "        'residplot'   - lot the residuals of a linear regression.\n",
        "\n",
        "        Matrix Plots\n",
        "        ---\n",
        "        'heatmap'     - Plot rectangular data as a color-encoded matrix.\n",
        "        'clustermap'  - Plot a matrix dataset as a hierarchically-clustered heatmap.\n",
        "\n",
        "        MULTI-PLOT GRIDS\n",
        "\n",
        "        FacetGrid\n",
        "        ---\n",
        "        'FacetGrid'   - Multi-plot grid for plotting conditional relationships.\n",
        "\n",
        "        Pair Grids\n",
        "        ---\n",
        "        'pairplot'    - Plot pairwise relationships in a dataset.\n",
        "        'PairGrid'    - Subplot grid for plotting pairwise relationships in a dataset.\n",
        "\n",
        "        Joint 'Grids'\n",
        "        ---\n",
        "        'jointplot'   - Draw a plot of two variables with bivariate and univariate graphs.\n",
        "        'JointGrid'   - Grid for drawing a bivariate plot with marginal univariate plots.\n",
        "    '''\n",
        "    # initialize plotting dict\n",
        "    graph_ = {\n",
        "        'relplot': sns.relplot,\n",
        "        'scatterplot': sns.scatterplot,\n",
        "        'lineplot': sns.lineplot,\n",
        "        'displot': sns.displot,\n",
        "        'histplot': sns.histplot,\n",
        "        'kdeplot': sns.kdeplot,\n",
        "        'ecdfplot': sns.ecdfplot,\n",
        "        'rugplot': sns.rugplot,\n",
        "        'catplot': sns.catplot,\n",
        "        'stripplot': sns.stripplot,\n",
        "        'swarmplot': sns.swarmplot,\n",
        "        'boxplot': sns.boxplot,\n",
        "        'violinplot': sns.violinplot,\n",
        "        'boxenplot': sns.boxenplot,\n",
        "        'pointplot': sns.pointplot,\n",
        "        'barplot': sns.barplot,\n",
        "        'countplot': sns.countplot,\n",
        "        'lmplot':' sns.lmplot',\n",
        "        'regplot': 'sns.regplot',\n",
        "        'residplot': 'sns.residplot',\n",
        "        'heatmap': 'sns.heatmap',\n",
        "        'clustermap': 'sns.clustermap',\n",
        "        'FacetGrid': 'sns.FacetGrid',\n",
        "        'pairplot': 'sns.pairplot',\n",
        "        'PairGrid': 'sns.PairGrid',\n",
        "        'jointplot': 'sns.jointplot',\n",
        "        'JointGrid': sns.JointGrid\n",
        "        }\n",
        "    # filter input for matching \n",
        "    feature = feature.title()\n",
        "    label = label.title()\n",
        "    # increase size for age\n",
        "    if (feature == 'Age') & (fig_size == 's'):\n",
        "        aging = True\n",
        "        while aging == True:\n",
        "            resp = input(f'This {feature} feature has quite the range!\\n\\\n",
        "            Would you like to increase the size for better readability?\\n\\n(y) or (n)   --> ')\n",
        "            if resp.lower() == 'n':\n",
        "                print(\"You know best!\")\n",
        "                aging = False\n",
        "            else:               # resp.lower() == 'y': \n",
        "                print(\"Great idea!\")\n",
        "                fig_size = 'm'\n",
        "                aging = False   \n",
        "    # plot\n",
        "    fig, ax = plt.subplots(figsize=sizes[fig_size])\n",
        "    graph_[plot_type](subset[feature],hue=subset[label])\n",
        "    plt.show() \n",
        "\n",
        "def plot_all_grep(feature, plot_type='countplot', fig_size='s',subset=train): \n",
        "    '''\n",
        "    **WRITE DOC**\n",
        "    '''\n",
        "    # filter input for matching \n",
        "    feature = feature.title()\n",
        "    # label = label.title()\n",
        "    # increase size for age\n",
        "    for i in range(1,(len(subset.columns)-1)):\n",
        "        by_feature = subset[subset.columns[i]]\n",
        "        if (subset.columns[i] == 'Age') & (fig_size == 's'):\n",
        "            # plot\n",
        "            fig, ax = plt.subplots(figsize=sizes['m'])\n",
        "            graph_[plot_type](by_feature,hue=subset[feature])\n",
        "            plt.show() \n",
        "        else:\n",
        "            # plot\n",
        "            fig, ax = plt.subplots(figsize=sizes[fig_size])\n",
        "            graph_[plot_type](by_feature,hue=subset[feature])\n",
        "            plt.show() "
      ],
      "metadata": {
        "id": "mU4o012PYDXr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Notes for later:\n",
        "# program a function that takes the correlations that a heatmap would show, \n",
        "# but prints grep graphs for each significant pairing:\n",
        "#   display corr for corr in corr_list if corr_val â‰¥ .5"
      ],
      "metadata": {
        "id": "cpoJieETppbP"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Impute NaN values"
      ],
      "metadata": {
        "id": "8vU3HMZDwOKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn_pandas import CategoricalImputer\n",
        "imputer = CategoricalImputer()\n",
        "\n",
        "def fill_nan(subset=None):\n",
        "    nan_list = []\n",
        "    null_count = subset.isnull().any()\n",
        "    for i in range(1,len(subset.columns)-1):\n",
        "        if null_count[i] == True:\n",
        "            nan_list.append(subset.columns[i])\n",
        "        else:\n",
        "            pass\n",
        "    for feature in nan_list:\n",
        "        subset[feature].fillna(inplace=True)\n",
        "        \n",
        "    print(subset.isnull().sum())\n"
      ],
      "metadata": {
        "id": "UXJFkxrLwcC2"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_copy_2 = train\n",
        "print(train.isnull().sum())\n",
        "fill_nan(train_copy_2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3ytBHmkxe2_",
        "outputId": "1841f77b-8980-4d25-88b0-1889412a5048"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID                 0\n",
            "Gender             0\n",
            "Ever_Married       0\n",
            "Age                0\n",
            "Graduated          0\n",
            "Profession         0\n",
            "Work_Experience    0\n",
            "Spending_Score     0\n",
            "Family_Size        0\n",
            "Var_1              0\n",
            "Segmentation       0\n",
            "train_y_n          0\n",
            "dtype: int64\n",
            "ID                 0\n",
            "Gender             0\n",
            "Ever_Married       0\n",
            "Age                0\n",
            "Graduated          0\n",
            "Profession         0\n",
            "Work_Experience    0\n",
            "Spending_Score     0\n",
            "Family_Size        0\n",
            "Var_1              0\n",
            "Segmentation       0\n",
            "train_y_n          0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summarize(train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uk71qlbI8WDV",
        "outputId": "faf97169-8bd4-4ba9-e631-5b03d4cfdcde"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary of Subset:  'train'\n",
            "\n",
            "\n",
            "--------\n",
            "DESCRIBE\n",
            "--------\n",
            "\n",
            "<bound method NDFrame.describe of           ID  Gender Ever_Married  Age Graduated     Profession  \\\n",
            "0     462809    Male           No   22        No     Healthcare   \n",
            "1     462643  Female          Yes   38       Yes       Engineer   \n",
            "2     466315  Female          Yes   67       Yes       Engineer   \n",
            "3     461735    Male          Yes   67       Yes         Lawyer   \n",
            "4     462669  Female          Yes   40       Yes  Entertainment   \n",
            "...      ...     ...          ...  ...       ...            ...   \n",
            "8063  464018    Male           No   22        No         Artist   \n",
            "8064  464685    Male           No   35        No      Executive   \n",
            "8065  465406  Female           No   33       Yes     Healthcare   \n",
            "8066  467299  Female           No   27       Yes     Healthcare   \n",
            "8067  461879    Male          Yes   37       Yes      Executive   \n",
            "\n",
            "      Work_Experience Spending_Score  Family_Size  Var_1 Segmentation  \\\n",
            "0                 1.0            Low          4.0  Cat_4            D   \n",
            "1                 1.0        Average          3.0  Cat_4            A   \n",
            "2                 1.0            Low          1.0  Cat_6            B   \n",
            "3                 0.0           High          2.0  Cat_6            B   \n",
            "4                 0.0           High          6.0  Cat_6            A   \n",
            "...               ...            ...          ...    ...          ...   \n",
            "8063              0.0            Low          7.0  Cat_1            D   \n",
            "8064              3.0            Low          4.0  Cat_4            D   \n",
            "8065              1.0            Low          1.0  Cat_6            D   \n",
            "8066              1.0            Low          4.0  Cat_6            B   \n",
            "8067              0.0        Average          3.0  Cat_4            B   \n",
            "\n",
            "      train_y_n  \n",
            "0             1  \n",
            "1             1  \n",
            "2             1  \n",
            "3             1  \n",
            "4             1  \n",
            "...         ...  \n",
            "8063          1  \n",
            "8064          1  \n",
            "8065          1  \n",
            "8066          1  \n",
            "8067          1  \n",
            "\n",
            "[8068 rows x 12 columns]>\n",
            "---\n",
            "\n",
            "--------\n",
            "INFO\n",
            "--------\n",
            "\n",
            "<bound method DataFrame.info of           ID  Gender Ever_Married  Age Graduated     Profession  \\\n",
            "0     462809    Male           No   22        No     Healthcare   \n",
            "1     462643  Female          Yes   38       Yes       Engineer   \n",
            "2     466315  Female          Yes   67       Yes       Engineer   \n",
            "3     461735    Male          Yes   67       Yes         Lawyer   \n",
            "4     462669  Female          Yes   40       Yes  Entertainment   \n",
            "...      ...     ...          ...  ...       ...            ...   \n",
            "8063  464018    Male           No   22        No         Artist   \n",
            "8064  464685    Male           No   35        No      Executive   \n",
            "8065  465406  Female           No   33       Yes     Healthcare   \n",
            "8066  467299  Female           No   27       Yes     Healthcare   \n",
            "8067  461879    Male          Yes   37       Yes      Executive   \n",
            "\n",
            "      Work_Experience Spending_Score  Family_Size  Var_1 Segmentation  \\\n",
            "0                 1.0            Low          4.0  Cat_4            D   \n",
            "1                 1.0        Average          3.0  Cat_4            A   \n",
            "2                 1.0            Low          1.0  Cat_6            B   \n",
            "3                 0.0           High          2.0  Cat_6            B   \n",
            "4                 0.0           High          6.0  Cat_6            A   \n",
            "...               ...            ...          ...    ...          ...   \n",
            "8063              0.0            Low          7.0  Cat_1            D   \n",
            "8064              3.0            Low          4.0  Cat_4            D   \n",
            "8065              1.0            Low          1.0  Cat_6            D   \n",
            "8066              1.0            Low          4.0  Cat_6            B   \n",
            "8067              0.0        Average          3.0  Cat_4            B   \n",
            "\n",
            "      train_y_n  \n",
            "0             1  \n",
            "1             1  \n",
            "2             1  \n",
            "3             1  \n",
            "4             1  \n",
            "...         ...  \n",
            "8063          1  \n",
            "8064          1  \n",
            "8065          1  \n",
            "8066          1  \n",
            "8067          1  \n",
            "\n",
            "[8068 rows x 12 columns]>\n",
            "---\n",
            "\n",
            "--------\n",
            "SHAPE\n",
            "--------\n",
            "\n",
            "(8068, 12)\n",
            "---\n",
            "\n",
            "--------\n",
            "ISNULL\n",
            "--------\n",
            "\n",
            "ID                 0\n",
            "Gender             0\n",
            "Ever_Married       0\n",
            "Age                0\n",
            "Graduated          0\n",
            "Profession         0\n",
            "Work_Experience    0\n",
            "Spending_Score     0\n",
            "Family_Size        0\n",
            "Var_1              0\n",
            "Segmentation       0\n",
            "train_y_n          0\n",
            "dtype: int64\n",
            "---\n",
            "\n",
            "--------\n",
            "CORR\n",
            "--------\n",
            "\n",
            "<bound method DataFrame.corr of           ID  Gender Ever_Married  Age Graduated     Profession  \\\n",
            "0     462809    Male           No   22        No     Healthcare   \n",
            "1     462643  Female          Yes   38       Yes       Engineer   \n",
            "2     466315  Female          Yes   67       Yes       Engineer   \n",
            "3     461735    Male          Yes   67       Yes         Lawyer   \n",
            "4     462669  Female          Yes   40       Yes  Entertainment   \n",
            "...      ...     ...          ...  ...       ...            ...   \n",
            "8063  464018    Male           No   22        No         Artist   \n",
            "8064  464685    Male           No   35        No      Executive   \n",
            "8065  465406  Female           No   33       Yes     Healthcare   \n",
            "8066  467299  Female           No   27       Yes     Healthcare   \n",
            "8067  461879    Male          Yes   37       Yes      Executive   \n",
            "\n",
            "      Work_Experience Spending_Score  Family_Size  Var_1 Segmentation  \\\n",
            "0                 1.0            Low          4.0  Cat_4            D   \n",
            "1                 1.0        Average          3.0  Cat_4            A   \n",
            "2                 1.0            Low          1.0  Cat_6            B   \n",
            "3                 0.0           High          2.0  Cat_6            B   \n",
            "4                 0.0           High          6.0  Cat_6            A   \n",
            "...               ...            ...          ...    ...          ...   \n",
            "8063              0.0            Low          7.0  Cat_1            D   \n",
            "8064              3.0            Low          4.0  Cat_4            D   \n",
            "8065              1.0            Low          1.0  Cat_6            D   \n",
            "8066              1.0            Low          4.0  Cat_6            B   \n",
            "8067              0.0        Average          3.0  Cat_4            B   \n",
            "\n",
            "      train_y_n  \n",
            "0             1  \n",
            "1             1  \n",
            "2             1  \n",
            "3             1  \n",
            "4             1  \n",
            "...         ...  \n",
            "8063          1  \n",
            "8064          1  \n",
            "8065          1  \n",
            "8066          1  \n",
            "8067          1  \n",
            "\n",
            "[8068 rows x 12 columns]>\n",
            "---\n",
            "\n",
            "--------\n",
            "DTYPES\n",
            "--------\n",
            "\n",
            "ID                   int64\n",
            "Gender              object\n",
            "Ever_Married        object\n",
            "Age                  int64\n",
            "Graduated           object\n",
            "Profession          object\n",
            "Work_Experience    float64\n",
            "Spending_Score      object\n",
            "Family_Size        float64\n",
            "Var_1               object\n",
            "Segmentation        object\n",
            "train_y_n            int64\n",
            "dtype: object\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_copy.isna().any()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sx7hiEZu4_eg",
        "outputId": "acd3a9cd-7e8f-42d3-d1db-fe88da6dd549"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID                 False\n",
              "Gender             False\n",
              "Ever_Married       False\n",
              "Age                False\n",
              "Graduated          False\n",
              "Profession         False\n",
              "Work_Experience    False\n",
              "Spending_Score     False\n",
              "Family_Size        False\n",
              "Var_1              False\n",
              "Segmentation       False\n",
              "train_y_n          False\n",
              "dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### OHE Function\n",
        "(Needed for further EDA)"
      ],
      "metadata": {
        "id": "qN-LwNcVlOcj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ohe(subset=None):\n",
        "    # must be run after fillna\n",
        "    obj_list = []\n",
        "    for i in range(1,len(subset.dtypes)-1):\n",
        "        if train.dtypes[i] == 'object':\n",
        "            obj_list.append(subset.columns[i]) \n",
        "        else:\n",
        "            pass\n",
        "    # print(obj_list)            \n",
        "    for feature in obj_list:\n",
        "        subset[feature].fillna(method='ffill',inplace=True)\n",
        "        print(\n",
        "            subset[feature],\n",
        "            \"ohe'd\" \n",
        "            )\n",
        "    # print(obj_list)      \n",
        "\n",
        "\n",
        "\n",
        "# for i in range(1,len(obj_list)-1):\n",
        "#     print(train.columns[i]) \n",
        "\n",
        "\n",
        "    # print(train.dtypes[i])\n",
        "    # print(train[train.columns[i]])\n",
        "    # print(train.columns[i].dtypes)\n",
        "\n",
        "# for var in train.dtypes:\n",
        "#     print(var)\n",
        "    \n",
        "#     if var == 'object':\n",
        "#         obj_list.append(train[var])\n",
        "#     else:\n",
        "#         print('no')\n"
      ],
      "metadata": {
        "id": "sS7fodk9tnFa"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ohe(comp_df2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Qn-dbeLugk5",
        "outputId": "c1a90b0e-d666-4bc9-f2bf-591c814bbb0a"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2622      Male\n",
            "2623    Female\n",
            "2624    Female\n",
            "2625      Male\n",
            "2626    Female\n",
            "Name: Gender, dtype: object ohe'd\n",
            "2622     No\n",
            "2623     No\n",
            "2624     No\n",
            "2625    Yes\n",
            "2626     No\n",
            "Name: Ever_Married, dtype: object ohe'd\n",
            "2622     No\n",
            "2623    Yes\n",
            "2624    Yes\n",
            "2625    Yes\n",
            "2626    Yes\n",
            "Name: Graduated, dtype: object ohe'd\n",
            "2622       Healthcare\n",
            "2623           Doctor\n",
            "2624    Entertainment\n",
            "2625        Executive\n",
            "2626       Healthcare\n",
            "Name: Profession, dtype: object ohe'd\n",
            "2622     Low\n",
            "2623     Low\n",
            "2624     Low\n",
            "2625    High\n",
            "2626     Low\n",
            "Name: Spending_Score, dtype: object ohe'd\n",
            "2622    Cat_6\n",
            "2623    Cat_6\n",
            "2624    Cat_6\n",
            "2625    Cat_4\n",
            "2626    Cat_7\n",
            "Name: Var_1, dtype: object ohe'd\n",
            "2622   NaN\n",
            "2623   NaN\n",
            "2624   NaN\n",
            "2625   NaN\n",
            "2626   NaN\n",
            "Name: Segmentation, dtype: float64 ohe'd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature engineering and transformation"
      ],
      "metadata": {
        "id": "k2LeKUflLehC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scratch"
      ],
      "metadata": {
        "id": "Gf0tX5h2WaUu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JGq4cFSLWi48"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obj_list = []\n",
        "for i in range(1,len(train.dtypes)-1):\n",
        "    if train.dtypes[i] == 'object':\n",
        "        obj_list.append(train.columns[i]) \n",
        "    else:\n",
        "        pass\n",
        "# for i in range(1,len(obj_list)-1):\n",
        "#     print(train.columns[i]) \n",
        "for item in obj_list:\n",
        "    print(train[item]) \n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "uFI8CYpdLhLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comp_df1['Ever_Married'].fillna(method='ffill',inplace=True)\n",
        "comp_df1['Profession'].fillna(method='ffill',inplace=True)\n",
        "comp_df1['Graduated'].fillna(method='bfill',inplace=True)\n",
        "comp_df1['Work_Experience'].fillna(method='bfill',inplace=True)\n",
        "comp_df1['Family_Size'].fillna(method='bfill',inplace=True)\n"
      ],
      "metadata": {
        "id": "soky9KZlZf5t"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train.isnull().sum()\n",
        "comp_df1.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4xPzo21ZmBG",
        "outputId": "7561faf7-e479-4080-c096-3e470c50de3f"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID                   int64\n",
              "Gender              object\n",
              "Ever_Married        object\n",
              "Age                  int64\n",
              "Graduated           object\n",
              "Profession          object\n",
              "Work_Experience    float64\n",
              "Spending_Score      object\n",
              "Family_Size        float64\n",
              "Var_1               object\n",
              "Segmentation        object\n",
              "train_y_n            int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dummy_df = pd.get_dummies(comp_df1)\n",
        "summarize(subset=dummy_df)\n",
        "print(\"\\n\\n=====================\\n\\n\")\n",
        "float_dummy_df =dummy_df.astype(float)\n",
        "# summarize(subset=float_dummy_df)\n"
      ],
      "metadata": {
        "id": "fpXqkx6pVRIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\n",
        "    float_dummy_df.isnull().sum(),\n",
        "    '\\n======\\n',\n",
        "    float_dummy_df.dtypes\n",
        "    )"
      ],
      "metadata": {
        "id": "pEo0-xmGYweQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dummy_df.dtypes)\n",
        "float_df =dummy_df.astype(float)\n",
        "print(float_df.dtypes)"
      ],
      "metadata": {
        "id": "SfW4dLdYVZZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 2. Training\n",
        "---\n",
        "* Traditional ML Modeling\n",
        "* Pure Torch Model\n",
        "* High-level Libraries and Tabular Frameworks"
      ],
      "metadata": {
        "id": "w1VzkVQAHh1h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Traditional ML modeling"
      ],
      "metadata": {
        "id": "c8XPEDl7ocFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here"
      ],
      "metadata": {
        "id": "BE3kYpzuqJyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pure `torch` model"
      ],
      "metadata": {
        "id": "D-_gt2iopuDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here"
      ],
      "metadata": {
        "id": "tJt0WDtKqLRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## High-level libraries and tabular frameworks"
      ],
      "metadata": {
        "id": "YUK7yRtEp2NA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here"
      ],
      "metadata": {
        "id": "MZZBEen8qMYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 3. Testing\n",
        "---\n",
        "* Model Selection and Test Set Evaluation\n",
        "* Notes and Findings"
      ],
      "metadata": {
        "id": "PUcW0hXbGRfz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model selection and test set evaluation"
      ],
      "metadata": {
        "id": "Q_arrqLoqADy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here"
      ],
      "metadata": {
        "id": "A2qfdqQsqNfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notes and findings\n",
        "\n",
        "What did you learn?"
      ],
      "metadata": {
        "id": "PHqN9LsZLpet"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A7KOEgi0KeBm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}